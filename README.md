# Overview / 概要
卒業研究で機械学習･深層学習を用いたオンライン試験のカンニング検出システムを作成する予定｡


## 具体的なシステムの流れ

1. リアルタイムにパソコンから得られるカメラデータから顔を検出する｡
2. 検出できた際にランドマークとしてデータを変換する｡
3. 変換されたデータに対して以下の機械学習モデルまたは深層学習モデルでカンニングを判定する｡
    1. 顔の傾きを特徴量として作成した学習モデル
    2. 目の黒目の位置を特徴量として作成した学習モデル
4. 2つのモデルによってカンニングとみなされる行為が該当した際に該当箇所に対して録画を行い別フォルダに保存を行う｡  

## 例としてdlibで得られたランドマークのイメージ
 ![68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3232343033342f37666162353734342d623739382d626432352d626336622d3937346334323961343761302e6a706567](https://user-images.githubusercontent.com/61785070/198558428-71dda8df-df04-4c80-b6a8-90a54c9669e9.jpeg)

## リアルタイムに検出した際の例
https://user-images.githubusercontent.com/61785070/187018179-158b2d4a-12da-4f39-87bc-b28eb6dba733.mov


## リアルタイムに黒目の位置を検出した際の例
https://user-images.githubusercontent.com/61785070/187086754-64145ac6-4318-4303-a5d0-93f30cf3b386.mov

